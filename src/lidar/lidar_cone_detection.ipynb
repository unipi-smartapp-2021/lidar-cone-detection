{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lidar_cone_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EloEarf7VhBV",
        "vzIHYzwWymd2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffd78hJqFPdH"
      },
      "source": [
        "# **Lidar cone detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3uEmrsvUxd0"
      },
      "source": [
        "## **Setup**\n",
        "\n",
        "Setup the repo and the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i3JABp6XVPU"
      },
      "source": [
        "### **Clone the repositories and import the libraries**\n",
        "\n",
        "Clone the repository from the smart application course organization and the one for the yolov5 model and import the libraries needed to work with the porject."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lFVzjLYHpRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80a73f84-dc06-413d-a065-da8159f11be4"
      },
      "source": [
        "!git clone --recurse-submodules \"https://github.com/unipi-smartapp-2021/sensory-cone-detection\"   # clone our repository\n",
        "!git clone \"https://github.com/ultralytics/yolov5\"  # clone the model repository"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sensory-cone-detection'...\n",
            "remote: Enumerating objects: 2925, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 2925 (delta 30), reused 18 (delta 11), pack-reused 2865\u001b[K\n",
            "Receiving objects: 100% (2925/2925), 121.78 MiB | 16.56 MiB/s, done.\n",
            "Resolving deltas: 100% (530/530), done.\n",
            "Submodule 'sensory/scripts/yolov5' (https://github.com/ultralytics/yolov5) registered for path 'sensory/scripts/yolov5'\n",
            "Submodule 'src/lidar/ros_numpy' (https://github.com/eric-wieser/ros_numpy) registered for path 'src/lidar/ros_numpy'\n",
            "Cloning into '/content/sensory-cone-detection/sensory/scripts/yolov5'...\n",
            "remote: Enumerating objects: 10491, done.        \n",
            "remote: Counting objects: 100% (3/3), done.        \n",
            "remote: Compressing objects: 100% (3/3), done.        \n",
            "remote: Total 10491 (delta 0), reused 3 (delta 0), pack-reused 10488        \n",
            "Receiving objects: 100% (10491/10491), 10.70 MiB | 3.43 MiB/s, done.\n",
            "Resolving deltas: 100% (7243/7243), done.\n",
            "Cloning into '/content/sensory-cone-detection/src/lidar/ros_numpy'...\n",
            "remote: Enumerating objects: 223, done.        \n",
            "remote: Counting objects: 100% (7/7), done.        \n",
            "remote: Compressing objects: 100% (5/5), done.        \n",
            "remote: Total 223 (delta 2), reused 6 (delta 2), pack-reused 216        \n",
            "Receiving objects: 100% (223/223), 38.59 KiB | 7.72 MiB/s, done.\n",
            "Resolving deltas: 100% (104/104), done.\n",
            "Submodule path 'sensory/scripts/yolov5': checked out '19c56e60b100cf8ff9af65b4347de69e0cff76ae'\n",
            "Submodule path 'src/lidar/ros_numpy': checked out 'b76f79c8dbe3866f39836d1e482d29cb20bb5e82'\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 10491, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 10491 (delta 0), reused 3 (delta 0), pack-reused 10488\u001b[K\n",
            "Receiving objects: 100% (10491/10491), 10.71 MiB | 7.78 MiB/s, done.\n",
            "Resolving deltas: 100% (7244/7244), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pypcd package has an error, fix it."
      ],
      "metadata": {
        "id": "CwRu0IWiW8if"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3z2VhLoZVd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8babf910-b944-49de-fe04-864063d51ee3"
      },
      "source": [
        "!pip install pypcd\n",
        "!sed -i \"s/import cStringIO as sio/from io import StringIO as sio/g\" ../usr/local/lib/python3.7/dist-packages/pypcd/pypcd.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypcd\n",
            "  Downloading pypcd-0.1.1-py2.py3-none-any.whl (22 kB)\n",
            "Collecting python-lzf\n",
            "  Downloading python-lzf-0.2.4.tar.gz (9.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pypcd) (1.19.5)\n",
            "Building wheels for collected packages: python-lzf\n",
            "  Building wheel for python-lzf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-lzf: filename=python_lzf-0.2.4-cp37-cp37m-linux_x86_64.whl size=23028 sha256=3a1570931266c9eadd4d4d52679e5d32b9fca844e9e85232baf1f193bd94ff56\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/5b/05/473bf0cd62eae63099399436edbaa0d54ae8de76c130d6d970\n",
            "Successfully built python-lzf\n",
            "Installing collected packages: python-lzf, pypcd\n",
            "Successfully installed pypcd-0.1.1 python-lzf-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsnHYOvsUxd9"
      },
      "source": [
        "Import the libraries and mount the drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLlfCk66Uxd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4a0f131-21c3-400f-b23e-6c59a19b7266"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "import tarfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # mount the drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_0Ud59-QO2t"
      },
      "source": [
        "### **Manage the dataset**\n",
        "\n",
        "If the dataset is inside a rosbag extract it, otherwise manage it with the manage_dataset.py method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXNkgK0RnbaS"
      },
      "source": [
        "with zipfile.ZipFile(\"/content/drive/Shareddrives/Sensory_data/medium_ds2.zip\", mode='r') as z:\n",
        "        z.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjszdXIf1af-"
      },
      "source": [
        "Manage the dataset by following what is suggested in https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data chapter 1.3. Keep in mind to modify the directory from which you're moving the images (ConeDataset for the first dataset or TRset for the full one).\n",
        "\n",
        "You can decide to convert the images to grayscale ones or not, then the dataset is splited into train, validation and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ofhspN2589x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a264d01a-e781-455a-c9bb-74171c677bca"
      },
      "source": [
        "!python sensory-cone-detection/src/manage_dataset.py --dataset medium_ds --path sensory-cone-detection/src/datasets/dataset_lidar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"sensory-cone-detection/src/manage_dataset.py\", line 96, in <module>\n",
            "    shutil.move(os.path.join(source, file_name), target_file)\n",
            "  File \"/usr/lib/python3.7/shutil.py\", line 564, in move\n",
            "    raise Error(\"Destination path '%s' already exists\" % real_dst)\n",
            "shutil.Error: Destination path 'sensory-cone-detection/src/datasets/dataset_lidar/labels/00699.txt' already exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EloEarf7VhBV"
      },
      "source": [
        "### **Check the yolov5 model and import the weights**\n",
        "\n",
        "Check if yolov5 is ready and fine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqN-E90RIJIn",
        "outputId": "00e5abe9-0d26-4523-dc52-553c664ece7f"
      },
      "source": [
        "%cd yolov5\n",
        "from yolov5.utils import notebook_init\n",
        "display = notebook_init()  # checks\n",
        "%cd ../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v6.0-185-g9b13a59 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 42.2/78.2 GB disk)\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install yolov5 requirements."
      ],
      "metadata": {
        "id": "BCYg-kxcx5c1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r yolov5/requirements.txt"
      ],
      "metadata": {
        "id": "RLcR5KxrvgES",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb91242f-b0d8-4c6a-d85d-babd91662ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 5)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 7)) (7.1.2)\n",
            "Collecting PyYAML>=5.3.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 12.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 11)) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 12)) (0.11.1+cu111)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 13)) (4.62.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 16)) (2.7.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 20)) (1.1.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 21)) (0.11.2)\n",
            "Collecting thop\n",
            "  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 4)) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 9)) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 11)) (3.10.0.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.35.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.42.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.37.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.4.6)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r yolov5/requirements.txt (line 20)) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (3.1.1)\n",
            "Installing collected packages: thop, PyYAML\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 thop-0.0.31.post2005241907\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "yaml"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th1yO-ZIRQqN"
      },
      "source": [
        "Import the yolov5 model, all the available models can be found here: https://github.com/ultralytics/yolov5/releases/."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd0dUn1QWhH_",
        "outputId": "335584ca-5cab-4153-bc00-4e2de81bce0e"
      },
      "source": [
        "import requests\n",
        "url = 'https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('yolov5s.pt', 'wb').write(r.content)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14698491"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzIHYzwWymd2"
      },
      "source": [
        "## **Convert from rosbag to pcd**\n",
        "\n",
        "If the dataset is inside a rosbag convert each message to a pcd file by calling the right method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VxbMA6AIbRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d16681c-408b-4265-e1ee-56f23be2999e"
      },
      "source": [
        "!python sensory-cone-detection/src/lidar/convert_rosbag_to_pcd.py --rosbag /content/lidar_dataset/2021-11-28-16-29-25.bag --path sensory-cone-detection/src/lidar/pcd_lidar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0% 0/1800 [00:00<?, ?it/s]95961901796\n",
            "\r  0% 0/1800 [00:00<?, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDyLo3UEWLpn"
      },
      "source": [
        "Save the pcd files inside a tar.gz by using the next command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thHeobMWtt2D"
      },
      "source": [
        "!python -m tarfile -c lidar_dataset.tar.gz \"lidar-cone-detection/src/Lidar/pcd_outputs/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPxg_OD_yvwH"
      },
      "source": [
        "## **Train the model**\n",
        "\n",
        "Train the model following the guide from https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2ZTpdvIrV13"
      },
      "source": [
        "**Main arguments:**\n",
        "*   *--img*, image size.\n",
        "*   *--batch*, batch size.\n",
        "*   *--epochs*, number of epochs.\n",
        "*   *--data*, the yaml file that specifies where datasets are.\n",
        "*   *--weights*, the model weights (you can find them here https://github.com/ultralytics/yolov5/releases).\n",
        "*   *--cache*, to save a cache file of the train and validation sets.\n",
        "*   *--project*, where to save the results.\n",
        "\n",
        "**An example of train call would be:**\n",
        "\n",
        "!python yolov5/train.py --img img_size --batch batch_size --epochs epochs --data dataset.yaml --weights model --cache --project runs/train\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXHb1S1INMPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f30f1ecc-e2db-47ff-8da0-935ef6955569"
      },
      "source": [
        "!python yolov5/train.py --img 480 --batch 16 --epochs 200 --data sensory-cone-detection/src/lidar/conedataset_lidar.yaml --weights yolov5s.pt --cache --project train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=sensory-cone-detection/src/lidar/conedataset_lidar.yaml, hyp=yolov5/data/hyps/hyp.scratch.yaml, epochs=200, batch_size=16, imgsz=480, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v6.0-185-g9b13a59 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model Summary: 270 layers, 7022326 parameters, 7022326 gradients, 15.8 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/sensory-cone-detection/src/datasets/dataset_lidar/train' images and labels...402 found, 78 missing, 1 empty, 0 corrupted: 100% 480/480 [00:00<00:00, 1347.58it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: sensory-cone-detection/src/datasets/dataset_lidar/images/00700.png: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: sensory-cone-detection/src/datasets/dataset_lidar/images/00701.png: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/sensory-cone-detection/src/datasets/dataset_lidar/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.3GB ram): 100% 480/480 [00:01<00:00, 420.35it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/sensory-cone-detection/src/datasets/dataset_lidar/validation' images and labels...52 found, 8 missing, 0 empty, 0 corrupted: 100% 60/60 [00:00<00:00, 765.48it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: sensory-cone-detection/src/datasets/dataset_lidar/images/001010.png: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/sensory-cone-detection/src/datasets/dataset_lidar/validation.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 60/60 [00:00<00:00, 182.61it/s]\n",
            "Plotting labels to train/exp/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m1.21 anchors/target, 0.505 Best Possible Recall (BPR). Anchors are a poor fit to dataset âš ï¸, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING: Extremely small objects found. 1037 of 2708 labels are < 3 pixels in size.\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2559 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.6301: 100% 1000/1000 [00:00<00:00, 1054.63it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.7740 best possible recall, 4.03 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=480, metric_all=0.267/0.596-mean/best, past_thr=0.501-mean: 6,2, 12,3, 11,5, 24,4, 11,9, 16,13, 54,5, 17,24, 430,3\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
            "Image sizes 480 train, 480 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mtrain/exp\u001b[0m\n",
            "Starting training for 200 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     0/199     1.89G     0.161   0.01595         0        91       480: 100% 30/30 [00:22<00:00,  1.33it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.52it/s]\n",
            "                 all         60          0          0          0          0          0\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     1/199     2.16G    0.1511   0.01428         0        63       480: 100% 30/30 [00:20<00:00,  1.46it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.73it/s]\n",
            "                 all         60          0          0          0          0          0\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     2/199     2.16G     0.144   0.01438         0        71       480: 100% 30/30 [00:20<00:00,  1.44it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.88it/s]\n",
            "                 all         60        352   0.000282    0.00852   8.46e-05   2.25e-05\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     3/199     2.16G    0.1394   0.01565         0        95       480: 100% 30/30 [00:20<00:00,  1.44it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.96it/s]\n",
            "                 all         60        352     0.0025    0.00852   0.000426     0.0001\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     4/199     2.16G    0.1319   0.01723         0       102       480: 100% 30/30 [00:21<00:00,  1.42it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.99it/s]\n",
            "                 all         60        352     0.0761     0.0795     0.0155    0.00282\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     5/199     2.16G    0.1212   0.01926         0        74       480: 100% 30/30 [00:20<00:00,  1.43it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.98it/s]\n",
            "                 all         60        352      0.036     0.0994     0.0118    0.00231\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     6/199     2.16G     0.113   0.01967         0        52       480: 100% 30/30 [00:20<00:00,  1.44it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.03it/s]\n",
            "                 all         60        352     0.0839      0.131     0.0256    0.00495\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     7/199     2.16G    0.1077   0.02027         0        55       480: 100% 30/30 [00:20<00:00,  1.45it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.08it/s]\n",
            "                 all         60        352       0.13      0.239     0.0439    0.00897\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     8/199     2.16G    0.1051   0.02054         0        53       480: 100% 30/30 [00:20<00:00,  1.43it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.13it/s]\n",
            "                 all         60        352      0.112      0.253     0.0472    0.00983\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     9/199     2.16G    0.1014   0.02052         0        61       480: 100% 30/30 [00:20<00:00,  1.44it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.13it/s]\n",
            "                 all         60        352      0.181       0.19     0.0746     0.0153\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "    10/199     2.16G   0.09925   0.02089         0        59       480: 100% 30/30 [00:20<00:00,  1.44it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.11it/s]\n",
            "                 all         60        352      0.296      0.168     0.0902     0.0169\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "    11/199     2.16G   0.09835   0.02103         0        55       480: 100% 30/30 [00:20<00:00,  1.44it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.20it/s]\n",
            "                 all         60        352      0.188      0.219     0.0948     0.0208\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "    12/199     2.16G   0.09696   0.02072         0        67       480: 100% 30/30 [00:20<00:00,  1.43it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.26it/s]\n",
            "                 all         60        352      0.244      0.253      0.132     0.0311\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "    13/199     2.16G   0.09647   0.02072         0        78       480: 100% 30/30 [00:20<00:00,  1.44it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.23it/s]\n",
            "                 all         60        352      0.241      0.278      0.112     0.0234\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "    14/199     2.16G   0.09596   0.02036         0        76       480: 100% 30/30 [00:20<00:00,  1.44it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.23it/s]\n",
            "                 all         60        352       0.29      0.284      0.136     0.0352\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "    15/199     2.16G    0.0939   0.02043         0        70       480: 100% 30/30 [00:20<00:00,  1.44it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.13it/s]\n",
            "                 all         60        352      0.308      0.256      0.144     0.0417\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "    16/199     2.16G   0.09803   0.01949         0        73       480: 100% 30/30 [00:20<00:00,  1.44it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.29it/s]\n",
            "                 all         60        352      0.256      0.216      0.101     0.0262\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "    17/199     2.16G   0.09724   0.01893         0        64       480: 100% 30/30 [00:20<00:00,  1.45it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.29it/s]\n",
            "                 all         60        352      0.305      0.224      0.143     0.0446\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "    18/199     2.16G   0.09666   0.02073         0        37       480: 100% 30/30 [00:20<00:00,  1.44it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.29it/s]\n",
            "                 all         60        352      0.248       0.21     0.0992     0.0207\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "    19/199     2.16G   0.09433    0.0197         0        72       480: 100% 30/30 [00:20<00:00,  1.45it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.32it/s]\n",
            "                 all         60        352      0.357      0.256       0.17     0.0427\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "    20/199     2.16G   0.09357   0.02038         0        79       480: 100% 30/30 [00:20<00:00,  1.45it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.29it/s]\n",
            "                 all         60        352      0.267      0.315      0.165     0.0487\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "    21/199     2.16G   0.09141   0.02036         0        57       480:  40% 12/30 [00:08<00:12,  1.44it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX6rTYFRqc5j"
      },
      "source": [
        "## **Evaluate the model**\n",
        "\n",
        "Use val.py if you have a test set defined in conedataset.yaml. Remember to use --task test or the model will work on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvKRe_Lmay1n"
      },
      "source": [
        "!python yolov5/val.py --weights drive/Shareddrives/Sensory_data/lidar_weights.pt --img 480 --conf 0.5 --data sensory-cone-detection/src/lidar/conedataset_lidar.yaml --task test --project test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ff4usNCqBQN"
      },
      "source": [
        "## **Inference**\n",
        "\n",
        "Use detect.py if you have no labeled images or you want to try the model on your custom data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IhZNvqDfJSc"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "start = np.floor(time.time()*1000)\n",
        "!rm -rf lidar_inference/exp\n",
        "print(np.floor(time.time()*1000-start))\n",
        "!python yolov5/detect.py --weights /content/drive/Shareddrives/Sensory_data/lidar_weights.pt --img 480 --conf 0.5 --source sensory-cone-detection/src/datasets/dataset_lidar/images/ --save-txt --project lidar_inference --hide-labels --line-thickness 2"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}