{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "camera_cone_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EX6rTYFRqc5j",
        "-Ff4usNCqBQN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svqgPR-uyZsY"
      },
      "source": [
        "# **StereoCamera cone detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzIHYzwWymd2"
      },
      "source": [
        "## **Setup**\n",
        "\n",
        "Setup the repo and the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i3JABp6XVPU"
      },
      "source": [
        "### **Clone the repositories and import the libraries**\n",
        "\n",
        "Clone the repository from the smart application course organization and the one for the yolov5 model and import the libraries needed to work with the porject."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lFVzjLYHpRh",
        "outputId": "60b1b379-6889-4148-ab8f-f9f7443a0aef"
      },
      "source": [
        "!git clone \"https://github.com/unipi-smartapp-2021/sensory-cone-detection\"   # clone our repository\n",
        "!git clone \"https://github.com/ultralytics/yolov5\"  # clone the model repository"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sensory-cone-detection'...\n",
            "remote: Enumerating objects: 2899, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 2899 (delta 15), reused 0 (delta 0), pack-reused 2865\u001b[K\n",
            "Receiving objects: 100% (2899/2899), 121.76 MiB | 13.77 MiB/s, done.\n",
            "Resolving deltas: 100% (515/515), done.\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 10488, done.\u001b[K\n",
            "remote: Total 10488 (delta 0), reused 0 (delta 0), pack-reused 10488\u001b[K\n",
            "Receiving objects: 100% (10488/10488), 10.70 MiB | 12.47 MiB/s, done.\n",
            "Resolving deltas: 100% (7243/7243), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ7gSjz9QLFw"
      },
      "source": [
        "Import the libraries and mount the drive."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install py7zr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmth3hn5zyY4",
        "outputId": "6e040eb1-6eb4-40e0-da2f-7ac43853e2f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting py7zr\n",
            "  Downloading py7zr-0.17.2-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting pyppmd>=0.17.0\n",
            "  Downloading pyppmd-0.17.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (126 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 126 kB 9.0 MB/s \n",
            "\u001b[?25hCollecting pyzstd>=0.14.4\n",
            "  Downloading pyzstd-0.15.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.4 MB 32.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from py7zr) (4.8.2)\n",
            "Collecting pycryptodomex>=3.6.6\n",
            "  Downloading pycryptodomex-3.12.0-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.0 MB 40.4 MB/s \n",
            "\u001b[?25hCollecting brotli>=1.0.9\n",
            "  Downloading Brotli-1.0.9-cp37-cp37m-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357 kB 51.6 MB/s \n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting texttable\n",
            "  Downloading texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pybcj>=0.5.0\n",
            "  Downloading pybcj-0.5.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->py7zr) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->py7zr) (3.6.0)\n",
            "Installing collected packages: texttable, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, brotli, py7zr\n",
            "Successfully installed brotli-1.0.9 multivolumefile-0.2.3 py7zr-0.17.2 pybcj-0.5.0 pycryptodomex-3.12.0 pyppmd-0.17.3 pyzstd-0.15.1 texttable-1.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-2P-LryDj9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c767495-e5f3-4845-88f0-ad208b1bf3a4"
      },
      "source": [
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import py7zr\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # mount the drive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_0Ud59-QO2t"
      },
      "source": [
        "### **Manage the dataset**\n",
        "\n",
        "There are two datasets, choose wisely:  \n",
        "- the first dataset is the small one and contains 101 images.\n",
        "- the second one contains more than 8000 images.\n",
        "- there will be more datasets in the future, or build one yourself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE1eopTKRpLs"
      },
      "source": [
        "import zipfile\n",
        "def extract7z(zip_path):\n",
        "    with py7zr.SevenZipFile(zip_path, mode='r') as z:\n",
        "        z.extractall()\n",
        "\n",
        "def extractzip(zip_path):\n",
        "    with zipfile.ZipFile(zip_path, mode='r') as z:\n",
        "        z.extractall()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyrlPZGpQJnk"
      },
      "source": [
        "datasets = [\"/content/drive/Shareddrives/Sensory_data/ConeDataset.7z\",\n",
        "            \"/content/drive/Shareddrives/Sensory_data/TRset-20211117T155203Z-001.zip\",\n",
        "            \"/content/drive/Shareddrives/Sensory_data/Recordings/cameras.zip\"]\n",
        "datasets_extract = [extract7z, extractzip]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "019-VzEdR2Rh"
      },
      "source": [
        "datasets_extract[1](datasets[1])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6nbWSNqR0bf"
      },
      "source": [
        "**Extract the chosen dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjszdXIf1af-"
      },
      "source": [
        "Manage the dataset by following what is suggested in https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data chapter 1.3. Keep in mind to modify the directory from which you're moving the images (ConeDataset for the first dataset or TRset for the full one).\n",
        "\n",
        "You can decide to convert the images to grayscale ones or not, then the dataset is splited into train, validation and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ofhspN2589x"
      },
      "source": [
        "!python sensory-cone-detection/src/manage_dataset.py --dataset TRset --path sensory-cone-detection/src/datasets/camera_dataset"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EloEarf7VhBV"
      },
      "source": [
        "### **Check the yolov5 model and import the weights**\n",
        "\n",
        "Check if yolov5 is ready and fine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqN-E90RIJIn",
        "outputId": "79073f58-e4e3-498d-8971-8ab27fe2c88c"
      },
      "source": [
        "%cd yolov5\n",
        "from yolov5.utils import notebook_init\n",
        "display = notebook_init()  # checks\n",
        "%cd ../"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v6.0-184-g6865d19 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 45.9/78.2 GB disk)\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install yolov5 requirements."
      ],
      "metadata": {
        "id": "BCYg-kxcx5c1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r yolov5/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RLcR5KxrvgES",
        "outputId": "93fb315b-ea09-4e69-c542-202357215b65"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 5)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 7)) (7.1.2)\n",
            "Collecting PyYAML>=5.3.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 11)) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 12)) (0.11.1+cu111)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 13)) (4.62.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 16)) (2.7.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 20)) (1.1.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r yolov5/requirements.txt (line 21)) (0.11.2)\n",
            "Collecting thop\n",
            "  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 4)) (3.0.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 9)) (2021.10.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 11)) (3.10.0.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.35.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.42.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.37.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r yolov5/requirements.txt (line 20)) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 16)) (3.1.1)\n",
            "Installing collected packages: thop, PyYAML\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 thop-0.0.31.post2005241907\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "yaml"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th1yO-ZIRQqN"
      },
      "source": [
        "Import the yolov5 model, all the available models can be found here: https://github.com/ultralytics/yolov5/releases/."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd0dUn1QWhH_",
        "outputId": "94df81d7-96c8-45af-a8b7-922d0c8313d1"
      },
      "source": [
        "import requests\n",
        "url = 'https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('yolov5s.pt', 'wb').write(r.content)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14698491"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPxg_OD_yvwH"
      },
      "source": [
        "## **Train the model**\n",
        "\n",
        "Train the model following the guide from https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2ZTpdvIrV13"
      },
      "source": [
        "**Main arguments:**\n",
        "*   *--img*, image size.\n",
        "*   *--batch*, batch size.\n",
        "*   *--epochs*, number of epochs.\n",
        "*   *--data*, the yaml file that specifies where datasets are.\n",
        "*   *--weights*, the model weights (you can find them here https://github.com/ultralytics/yolov5/releases).\n",
        "*   *--cache*, to save a cache file of the train and validation sets.\n",
        "*   *--project*, where to save the results.\n",
        "\n",
        "**An example of train call would be:**\n",
        "\n",
        "!python yolov5/train.py --img img_size --batch batch_size --epochs epochs --data dataset.yaml --weights model --cache --project runs/train\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXHb1S1INMPi"
      },
      "source": [
        "!python yolov5/train.py --img 640 --batch 64 --epochs 10 --data sensory-cone-detection/src/stereocamera/conedataset_camera.yaml --weights sensory-cone-detection/src/stereocamera/best.pt --cache --project train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2W94swlV2aS"
      },
      "source": [
        "Use the tensorboard to see the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjflIYvMNEej"
      },
      "source": [
        "# Tensorboard  (optional)\n",
        "%reload_ext tensorboard\n",
        "#%load_ext tensorboard\n",
        "%tensorboard --logdir train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX6rTYFRqc5j"
      },
      "source": [
        "## **Evaluate the model**\n",
        "\n",
        "Use val.py if you have a test set defined in conedataset.yaml. Remember to use --task test or the model will work on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY6M2bbEov8A",
        "outputId": "8d89a003-4c77-4f4e-a4c7-d1da571f9a69"
      },
      "source": [
        "!python yolov5/val.py --weights /content/train/exp5/weights/best.pt --img 640 --conf 0.5 --data sensory-cone-detection/src/stereocamera/conedataset_camera.yaml --task test --project runs/test"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=sensory-cone-detection/src/stereocamera/conedataset_camera.yaml, weights=['/content/train/exp5/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.5, iou_thres=0.6, task=test, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/test, name=exp, exist_ok=False, half=False, dnn=False\n",
            "WARNING: confidence threshold 0.5 >> 0.001 will produce invalid mAP values.\n",
            "YOLOv5 ðŸš€ v6.0-184-g6865d19 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning '/content/sensory-cone-detection/src/datasets/camera_dataset/test' images and labels...862 found, 6 missing, 0 empty, 1 corrupted: 100% 868/868 [00:02<00:00, 299.15it/s]\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mWARNING: sensory-cone-detection/src/datasets/camera_dataset/images/Aidlingen_07_12_video_first_frame_5.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.6951      1.6958      1.6958      1.6958      1.5159      1.5159      1.6031      1.6055]\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /content/sensory-cone-detection/src/datasets/camera_dataset/test.cache\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 28/28 [00:34<00:00,  1.23s/it]\n",
            "                 all        867       6298      0.961      0.857      0.922       0.67\n",
            "                 big        867        256      0.967      0.808      0.897      0.678\n",
            "              orange        867       1244      0.963      0.826      0.906      0.643\n",
            "              yellow        867       2377      0.959      0.889      0.938      0.674\n",
            "                blue        867       2421      0.958      0.904      0.945      0.683\n",
            "Speed: 0.2ms pre-process, 13.4ms inference, 2.5ms NMS per image at shape (32, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/test/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ff4usNCqBQN"
      },
      "source": [
        "## **Inference**\n",
        "\n",
        "Use detect.py if you have no labeled images or you want to try the model on your custom data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ebRgAKBMBP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26ffdee4-b6b1-4fd6-ca5b-aed96322ad35"
      },
      "source": [
        "!rm -rf detect/exp\n",
        "!python yolov5/detect.py --weights /content/sensory-cone-detection/src/stereocamera/best.pt --img 640 --conf 0.5 --source /content/b83381bf-ad73-4b73-a674-930f48594e61.jpg --exist-ok --save-txt --project detect --hide-labels --line-thickness 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/lidar-cone-detection/src/stereocamera/best.pt'], source=/content/b83381bf-ad73-4b73-a674-930f48594e61.jpg, imgsz=[640, 640], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=True, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 ðŸš€ v6.0-124-g1075488 torch 1.10.0+cu111 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/1 /content/b83381bf-ad73-4b73-a674-930f48594e61.jpg: 640x384 3 oranges, Done. (0.224s)\n",
            "Speed: 2.4ms pre-process, 224.4ms inference, 12.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mdetect/exp\u001b[0m\n",
            "1 labels saved to detect/exp/labels\n"
          ]
        }
      ]
    }
  ]
}